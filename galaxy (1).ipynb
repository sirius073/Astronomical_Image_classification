{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3175,"databundleVersionId":44352,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport random\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport torchvision.transforms.functional as TF\nfrom transformers import AutoImageProcessor, ResNetForImageClassification\nimport torch\nimport pandas as pd\nimport os\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:27:19.442406Z","iopub.execute_input":"2024-11-29T09:27:19.442805Z","iopub.status.idle":"2024-11-29T09:27:35.780771Z","shell.execute_reply.started":"2024-11-29T09:27:19.442753Z","shell.execute_reply":"2024-11-29T09:27:35.779938Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import zipfile\nimport os\n\nzip_file_path = '/kaggle/input/galaxy-zoo-the-galaxy-challenge/images_training_rev1.zip' \nextract_dir = '/kaggle/working/unzipped_images' \n\nos.makedirs(extract_dir, exist_ok=True)\n\nwith zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_dir)\n\nprint(f\"Files extracted to: {extract_dir}\")\n\nextracted_files = os.listdir(extract_dir)\nprint(\"Extracted files:\", extracted_files)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:27:42.958494Z","iopub.execute_input":"2024-11-29T09:27:42.959143Z","iopub.status.idle":"2024-11-29T09:28:01.726893Z","shell.execute_reply.started":"2024-11-29T09:27:42.959103Z","shell.execute_reply":"2024-11-29T09:28:01.725891Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Files extracted to: /kaggle/working/unzipped_images\nExtracted files: ['images_training_rev1']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"labels_csv='/kaggle/input/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.zip'\nimages_folder='/kaggle/working/unzipped_images/images_training_rev1'\nlabels_df=pd.read_csv(labels_csv)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:05.238726Z","iopub.execute_input":"2024-11-29T09:28:05.239081Z","iopub.status.idle":"2024-11-29T09:28:05.611746Z","shell.execute_reply.started":"2024-11-29T09:28:05.239050Z","shell.execute_reply":"2024-11-29T09:28:05.610912Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Now importantly, I went through the paper of galaxy-zoo and found that each image can be classified into multiple subclasses and there is no regularity in it. Basically each class has other classes linked to it too so it wasnt fair to classify it into a single subclass only out of 37. For example, if an image is belonging to class 1 it may also belong to class 3 and 7 further (just an example) and further subclasses (there is diagram given on net that i accessed to get such understanding). Therefore, according my understanding, the subclass 1.1 belonged to elliptical galaxies, subclass 1.2 belonged to lenticular galaxies and subclass 1.3 belonged to ones which dont have any particular shape. This was the broadest classification into galaxies only that has no contradictions with other classes and also all other classes and subclasses are linked to these in some way so it seemed fair to do this. Thus i am doing this classification only in my notebook.","metadata":{}},{"cell_type":"code","source":"class1_df = labels_df[['GalaxyID', 'Class1.1', 'Class1.2', 'Class1.3']].copy()\nclass1_df.rename(columns={\n    'Class1.1': 'elliptical',\n    'Class1.2': 'lenticular',\n    'Class1.3': 'other'\n}, inplace=True)\n\nclass1_df","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:10.354663Z","iopub.execute_input":"2024-11-29T09:28:10.355394Z","iopub.status.idle":"2024-11-29T09:28:10.381423Z","shell.execute_reply.started":"2024-11-29T09:28:10.355359Z","shell.execute_reply":"2024-11-29T09:28:10.380673Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       GalaxyID  elliptical  lenticular     other\n0        100008    0.383147    0.616853  0.000000\n1        100023    0.327001    0.663777  0.009222\n2        100053    0.765717    0.177352  0.056931\n3        100078    0.693377    0.238564  0.068059\n4        100090    0.933839    0.000000  0.066161\n...         ...         ...         ...       ...\n61573    999948    0.510379    0.489621  0.000000\n61574    999950    0.901216    0.098784  0.000000\n61575    999958    0.202841    0.777376  0.019783\n61576    999964    0.091000    0.909000  0.000000\n61577    999967    0.767000    0.140000  0.093000\n\n[61578 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GalaxyID</th>\n      <th>elliptical</th>\n      <th>lenticular</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100008</td>\n      <td>0.383147</td>\n      <td>0.616853</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100023</td>\n      <td>0.327001</td>\n      <td>0.663777</td>\n      <td>0.009222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100053</td>\n      <td>0.765717</td>\n      <td>0.177352</td>\n      <td>0.056931</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100078</td>\n      <td>0.693377</td>\n      <td>0.238564</td>\n      <td>0.068059</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100090</td>\n      <td>0.933839</td>\n      <td>0.000000</td>\n      <td>0.066161</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61573</th>\n      <td>999948</td>\n      <td>0.510379</td>\n      <td>0.489621</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>61574</th>\n      <td>999950</td>\n      <td>0.901216</td>\n      <td>0.098784</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>61575</th>\n      <td>999958</td>\n      <td>0.202841</td>\n      <td>0.777376</td>\n      <td>0.019783</td>\n    </tr>\n    <tr>\n      <th>61576</th>\n      <td>999964</td>\n      <td>0.091000</td>\n      <td>0.909000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>61577</th>\n      <td>999967</td>\n      <td>0.767000</td>\n      <td>0.140000</td>\n      <td>0.093000</td>\n    </tr>\n  </tbody>\n</table>\n<p>61578 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def one_hot_encode(row):\n    max_value = max(row['elliptical'], row['lenticular'], row['other'])\n    if max_value == row['elliptical']:\n        return pd.Series({'elliptical': 1, 'lenticular': 0, 'other': 0})\n    elif max_value == row['lenticular']:\n        return pd.Series({'elliptical': 0, 'lenticular': 1, 'other': 0})\n    else:\n        return pd.Series({'elliptical': 0, 'lenticular': 0, 'other': 1})\n\none_hot_df = class1_df[['GalaxyID']].copy()\none_hot_df = one_hot_df.join(class1_df.apply(one_hot_encode, axis=1))\n\nprint(one_hot_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:14.359268Z","iopub.execute_input":"2024-11-29T09:28:14.359952Z","iopub.status.idle":"2024-11-29T09:28:27.166523Z","shell.execute_reply.started":"2024-11-29T09:28:14.359919Z","shell.execute_reply":"2024-11-29T09:28:27.165452Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   GalaxyID  elliptical  lenticular  other\n0    100008           0           1      0\n1    100023           0           1      0\n2    100053           1           0      0\n3    100078           1           0      0\n4    100090           1           0      0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nones_count = one_hot_df[['elliptical', 'lenticular', 'other']].sum()\n\nprint(ones_count)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:27.168115Z","iopub.execute_input":"2024-11-29T09:28:27.168462Z","iopub.status.idle":"2024-11-29T09:28:27.176419Z","shell.execute_reply.started":"2024-11-29T09:28:27.168428Z","shell.execute_reply":"2024-11-29T09:28:27.175451Z"},"trusted":true},"outputs":[{"name":"stdout","text":"elliptical    26693\nlenticular    34826\nother            59\ndtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Since the number of other galaxies are very low and almost negligible, i ll focus primarily on the other two only and remove the other column from my dataset","metadata":{}},{"cell_type":"code","source":"\nfiltered_df = one_hot_df[(one_hot_df['elliptical'] != 0) | (one_hot_df['lenticular'] != 0)]\n\nprint(filtered_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:27.177904Z","iopub.execute_input":"2024-11-29T09:28:27.178231Z","iopub.status.idle":"2024-11-29T09:28:27.194849Z","shell.execute_reply.started":"2024-11-29T09:28:27.178199Z","shell.execute_reply":"2024-11-29T09:28:27.193685Z"},"trusted":true},"outputs":[{"name":"stdout","text":"       GalaxyID  elliptical  lenticular  other\n0        100008           0           1      0\n1        100023           0           1      0\n2        100053           1           0      0\n3        100078           1           0      0\n4        100090           1           0      0\n...         ...         ...         ...    ...\n61573    999948           1           0      0\n61574    999950           1           0      0\n61575    999958           0           1      0\n61576    999964           0           1      0\n61577    999967           1           0      0\n\n[61519 rows x 4 columns]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"label_df = filtered_df.drop(columns=['other'])\n\nlabel_df['label'] = label_df['elliptical'].apply(lambda x: 1 if x == 1 else 0)\n\nlabel_df = label_df.drop(columns=['elliptical', 'lenticular'])","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:27.197033Z","iopub.execute_input":"2024-11-29T09:28:27.197321Z","iopub.status.idle":"2024-11-29T09:28:27.226627Z","shell.execute_reply.started":"2024-11-29T09:28:27.197280Z","shell.execute_reply":"2024-11-29T09:28:27.225766Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"label_df","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:27.227716Z","iopub.execute_input":"2024-11-29T09:28:27.227992Z","iopub.status.idle":"2024-11-29T09:28:27.237126Z","shell.execute_reply.started":"2024-11-29T09:28:27.227964Z","shell.execute_reply":"2024-11-29T09:28:27.236099Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       GalaxyID  label\n0        100008      0\n1        100023      0\n2        100053      1\n3        100078      1\n4        100090      1\n...         ...    ...\n61573    999948      1\n61574    999950      1\n61575    999958      0\n61576    999964      0\n61577    999967      1\n\n[61519 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GalaxyID</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100008</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100023</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100053</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100078</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100090</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61573</th>\n      <td>999948</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>61574</th>\n      <td>999950</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>61575</th>\n      <td>999958</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>61576</th>\n      <td>999964</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>61577</th>\n      <td>999967</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>61519 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Now i access the resnet50 model from the huggingface platform and get it ready for binary classification","metadata":{}},{"cell_type":"code","source":"\nprocessor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\nmodel = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n\nnum_classes = 1\nin_features = model.classifier[-1].in_features \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.classifier[-1] = nn.Linear(in_features, num_classes)\nmodel.to(device) \n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T13:55:29.030956Z","iopub.execute_input":"2024-11-10T13:55:29.031591Z","iopub.status.idle":"2024-11-10T13:55:30.852986Z","shell.execute_reply.started":"2024-11-10T13:55:29.031548Z","shell.execute_reply":"2024-11-10T13:55:30.852027Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"224c649987944c249d180a1fd6901c2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"041f0f67ad2a421cb94e0c0aaad2337c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"123b3c1acec74454bde50a8037cfaa53"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"ResNetForImageClassification(\n  (resnet): ResNetModel(\n    (embedder): ResNetEmbeddings(\n      (embedder): ResNetConvLayer(\n        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU()\n      )\n      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )\n    (encoder): ResNetEncoder(\n      (stages): ModuleList(\n        (0): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n        (1): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (3): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n        (2): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (3): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (4): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (5): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n        (3): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n      )\n    )\n    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=2048, out_features=1, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"torch.save(model.state_dict(),'raw_resnet50.pth')","metadata":{"execution":{"iopub.status.busy":"2024-11-10T13:55:36.721644Z","iopub.execute_input":"2024-11-10T13:55:36.722338Z","iopub.status.idle":"2024-11-10T13:55:36.876255Z","shell.execute_reply.started":"2024-11-10T13:55:36.722285Z","shell.execute_reply":"2024-11-10T13:55:36.875411Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Preparation of dataset for evalutation and training...note i also included the transformation like random cropping, rotating, contrast and brightness to make the data more diverse.","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport random\nimport torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\n\nclass GalaxyBrightness(object):\n    \"\"\"Custom transform to adjust galaxy brightness.\"\"\"\n    def __init__(self, brightness_range=(0.8, 1.2)):\n        self.brightness_range = brightness_range\n    \n    def __call__(self, img):\n        brightness = random.uniform(self.brightness_range[0], self.brightness_range[1])\n        return TF.adjust_brightness(img, brightness)\n\nclass GalaxyContrast(object):\n    \"\"\"Custom transform to adjust galaxy contrast.\"\"\"\n    def __init__(self, contrast_range=(0.8, 1.2)):\n        self.contrast_range = contrast_range\n    \n    def __call__(self, img):\n        contrast = random.uniform(self.contrast_range[0], self.contrast_range[1])\n        return TF.adjust_contrast(img, contrast)\n\nclass GalaxyZooDataset(Dataset):\n    def __init__(self, images_folder, labels_df, train=True):\n        self.images_folder = images_folder\n        self.labels_df = labels_df \n        self.train = train  \n\n        self.transform_train = transforms.Compose([\n            transforms.RandomRotation(360),\n            transforms.CenterCrop([256, 256]),\n            transforms.Resize([128, 128]),\n            GalaxyBrightness(),\n            GalaxyContrast(),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n        ])\n            \n        self.transform_val = transforms.Compose([\n            transforms.CenterCrop([256, 256]),\n            transforms.Resize([128, 128]),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n        ])\n\n    def __len__(self):\n        return len(self.labels_df)\n\n    def __getitem__(self, idx):\n        image_id = str(self.labels_df.iloc[idx, 0])  \n        label = self.labels_df.iloc[idx, 1] \n\n        image_path = os.path.join(self.images_folder, f\"{image_id}.jpg\")\n        try:\n            image = Image.open(image_path).convert('RGB')  # Convert to RGB\n        except FileNotFoundError:\n            raise FileNotFoundError(f\"Image {image_path} not found.\")\n\n        # Apply transformations\n        if self.train:\n            image = self.transform_train(image)\n        else:\n            image = self.transform_val(image)\n\n        return image, torch.tensor(label, dtype=torch.float32)  \n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:40.502661Z","iopub.execute_input":"2024-11-29T09:28:40.503299Z","iopub.status.idle":"2024-11-29T09:28:40.514489Z","shell.execute_reply.started":"2024-11-29T09:28:40.503266Z","shell.execute_reply":"2024-11-29T09:28:40.513434Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df,val_df=train_test_split(label_df,test_size=0.2,random_state=42)\nval_dataset = GalaxyZooDataset(images_folder, val_df,train=False)\ntrain_dataset = GalaxyZooDataset(images_folder, train_df,train=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:49.935316Z","iopub.execute_input":"2024-11-29T09:28:49.936429Z","iopub.status.idle":"2024-11-29T09:28:49.949637Z","shell.execute_reply.started":"2024-11-29T09:28:49.936371Z","shell.execute_reply":"2024-11-29T09:28:49.948800Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:28:56.060258Z","iopub.execute_input":"2024-11-29T09:28:56.060615Z","iopub.status.idle":"2024-11-29T09:28:56.066240Z","shell.execute_reply.started":"2024-11-29T09:28:56.060582Z","shell.execute_reply":"2024-11-29T09:28:56.065242Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(49215, 2)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndef evaluate_model(model, data_loader, device):\n    model.eval()  # Set model to evaluation mode\n    total_correct = 0\n    total_samples = 0\n    \n    # Use tqdm to display a progress bar\n    with torch.no_grad(): \n        for images, labels in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            \n            # Forward pass\n            outputs = model(images)\n            \n            # Access the logits from the outputs\n            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n            \n            # Apply sigmoid activation to get probabilities\n            probabilities = torch.sigmoid(logits)\n            \n            # Get predictions by thresholding at 0.5\n            predictions = (probabilities >= 0.5).float()  # Convert probabilities to binary predictions\n            \n            # Since we have only one output node, we compare directly\n            correct_labels = labels.view(-1, 1)  # Ensure labels are in the correct shape\n            total_correct += (predictions == correct_labels).sum().item()\n            total_samples += labels.size(0)\n\n    # Calculate and print overall accuracy\n    accuracy = total_correct / total_samples\n    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n    \n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T13:55:43.368688Z","iopub.execute_input":"2024-11-10T13:55:43.369323Z","iopub.status.idle":"2024-11-10T13:55:43.378474Z","shell.execute_reply.started":"2024-11-10T13:55:43.369271Z","shell.execute_reply":"2024-11-10T13:55:43.377589Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"evaluate_model(model, val_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T13:55:45.129597Z","iopub.execute_input":"2024-11-10T13:55:45.129963Z","iopub.status.idle":"2024-11-10T13:56:30.369499Z","shell.execute_reply.started":"2024-11-10T13:55:45.129926Z","shell.execute_reply":"2024-11-10T13:56:30.368562Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 43.41%\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.4340864759427828"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"Therefore the accuracy without finetuning reaches 43.41%.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\ndef train_model(model, train_loader, val_loader, device, num_epochs=10, learning_rate=0.001):\n    criterion = nn.BCEWithLogitsLoss()  # Use BCE with logits for binary classification\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n\n    best_val_accuracy = 0  # Track best validation accuracy for model saving\n\n    for epoch in range(num_epochs):\n        model.train()  \n        total_loss = 0\n        total_correct = 0\n        total_samples = 0\n\n        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n            for batch_idx, (images, labels) in enumerate(train_loader):\n                images, labels = images.to(device), labels.float().to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(images)\n                \n                # Check if outputs contains logits attribute (for models from transformers)\n                if hasattr(outputs, 'logits'):\n                    logits = outputs.logits.squeeze()  \n                else:\n                    logits = outputs.squeeze()  # Direct tensor output for torchvision models\n\n                loss = criterion(logits, labels)  # Compute the loss\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item()\n                predictions = torch.sigmoid(logits)  # Apply sigmoid to get probabilities\n                predicted_labels = (predictions >= 0.5).float()  # Threshold at 0.5\n                \n                total_correct += (predicted_labels == labels).sum().item()\n                total_samples += labels.size(0)\n\n                # Update progress bar every 5 batches to avoid high frequency of updates\n                if batch_idx % 5 == 0:\n                    pbar.set_postfix(loss=total_loss / (pbar.n + 1), accuracy=total_correct / total_samples * 100)\n                    pbar.update(5)  # Only update every 5 batches\n        \n        scheduler.step()\n\n        avg_loss = total_loss / len(train_loader)\n        avg_accuracy = total_correct / total_samples * 100\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.2f}%\")\n\n        # Validation phase\n        model.eval()\n        total_correct_val = 0\n        total_samples_val = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.float().to(device)\n\n                outputs = model(images)\n                \n                # Again, check if logits are wrapped\n                if hasattr(outputs, 'logits'):\n                    logits = outputs.logits.squeeze()\n                else:\n                    logits = outputs.squeeze()\n\n                predictions = torch.sigmoid(logits)  \n                predicted_labels = (predictions >= 0.5).float()  \n\n                total_correct_val += (predicted_labels == labels).sum().item()\n                total_samples_val += labels.size(0)\n\n        val_accuracy = total_correct_val / total_samples_val * 100\n        print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n        # Save the model if validation accuracy improves\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            torch.save(model.state_dict(), \"best_model.pth\")\n            print(f\"Model saved with validation accuracy: {val_accuracy:.2f}%\")\n\n# Example usage\n# Assuming `train_loader` and `val_loader` are DataLoader objects, and the model is define\n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:29:21.827742Z","iopub.execute_input":"2024-11-29T09:29:21.828061Z","iopub.status.idle":"2024-11-29T09:29:21.839641Z","shell.execute_reply.started":"2024-11-29T09:29:21.828032Z","shell.execute_reply":"2024-11-29T09:29:21.838708Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, device, num_epochs=4, learning_rate=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T14:40:37.157026Z","iopub.execute_input":"2024-11-10T14:40:37.157412Z","iopub.status.idle":"2024-11-10T15:05:26.326095Z","shell.execute_reply.started":"2024-11-10T14:40:37.157374Z","shell.execute_reply":"2024-11-10T15:05:26.325155Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/4: 1540batch [05:28,  4.69batch/s, accuracy=83, loss=0.38]                          \n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/4], Loss: 0.3803, Accuracy: 82.96%\nValidation Accuracy: 84.83%\nModel saved with validation accuracy: 84.83%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4: 1540batch [05:30,  4.66batch/s, accuracy=85.4, loss=0.333]                       \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/4], Loss: 0.3330, Accuracy: 85.39%\nValidation Accuracy: 83.43%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4: 1540batch [05:29,  4.68batch/s, accuracy=85.7, loss=0.326]                       \n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/4], Loss: 0.3263, Accuracy: 85.68%\nValidation Accuracy: 83.18%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/4: 1540batch [05:28,  4.68batch/s, accuracy=86.9, loss=0.298]                       \n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/4], Loss: 0.2981, Accuracy: 86.89%\nValidation Accuracy: 86.74%\nModel saved with validation accuracy: 86.74%\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"So the final accuracy for completely fine tuned model of resnet50 comes 86.74%.","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"fine_tuned_resnet50.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T15:06:20.851681Z","iopub.execute_input":"2024-11-10T15:06:20.852532Z","iopub.status.idle":"2024-11-10T15:06:21.005424Z","shell.execute_reply.started":"2024-11-10T15:06:20.852489Z","shell.execute_reply":"2024-11-10T15:06:21.004430Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"Setup of LoRA model, freezing all the upper layers of the base model, and unfreezing of lora layers for training.","metadata":{}},{"cell_type":"code","source":"\nclass LORALayer(nn.Module):\n    def __init__(self, input_dim, output_dim, rank=64):\n        super(LORALayer, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.rank = rank\n\n        # LoRA parameters\n        self.A = nn.Parameter(torch.randn(input_dim, rank) * 0.01)\n        self.B = nn.Parameter(torch.randn(rank, output_dim) * 0.01)\n\n        # Base layer (frozen)\n        self.base_layer = nn.Linear(input_dim, output_dim)\n        self.base_layer.weight.requires_grad = False\n        self.base_layer.bias.requires_grad = False\n\n    def forward(self, x):\n        original_output = self.base_layer(x)\n        low_rank_update = x @ self.A @ self.B\n        return original_output + low_rank_update\n\nprocessor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\nmodel = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n\nnum_features = model.classifier[-1].in_features  # Last layer of classifier\n\nlora_layer = LORALayer(input_dim=num_features, output_dim=1, rank=64).to(device)\nmodel.classifier = nn.Sequential(\n    nn.Flatten(),\n    lora_layer\n).to(device)\n\n# Freeze all parameters except LoRA\nfor param in model.parameters():\n    param.requires_grad = False\nfor param in lora_layer.parameters():\n    param.requires_grad = True\n","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:53:51.070674Z","iopub.execute_input":"2024-11-29T09:53:51.071395Z","iopub.status.idle":"2024-11-29T09:53:51.461423Z","shell.execute_reply.started":"2024-11-29T09:53:51.071362Z","shell.execute_reply":"2024-11-29T09:53:51.460672Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T09:53:54.509834Z","iopub.execute_input":"2024-11-29T09:53:54.510527Z","iopub.status.idle":"2024-11-29T09:53:54.565874Z","shell.execute_reply.started":"2024-11-29T09:53:54.510481Z","shell.execute_reply":"2024-11-29T09:53:54.564918Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"ResNetForImageClassification(\n  (resnet): ResNetModel(\n    (embedder): ResNetEmbeddings(\n      (embedder): ResNetConvLayer(\n        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU()\n      )\n      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )\n    (encoder): ResNetEncoder(\n      (stages): ModuleList(\n        (0): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n        (1): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (3): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n        (2): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (3): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (4): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (5): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n        (3): ResNetStage(\n          (layers): Sequential(\n            (0): ResNetBottleNeckLayer(\n              (shortcut): ResNetShortCut(\n                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (1): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n            (2): ResNetBottleNeckLayer(\n              (shortcut): Identity()\n              (layer): Sequential(\n                (0): ResNetConvLayer(\n                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (1): ResNetConvLayer(\n                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): ReLU()\n                )\n                (2): ResNetConvLayer(\n                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                  (activation): Identity()\n                )\n              )\n              (activation): ReLU()\n            )\n          )\n        )\n      )\n    )\n    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): LORALayer(\n      (base_layer): Linear(in_features=2048, out_features=1, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, device, num_epochs=2, learning_rate=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T09:53:55.550364Z","iopub.execute_input":"2024-11-29T09:53:55.551041Z","iopub.status.idle":"2024-11-29T10:03:14.610306Z","shell.execute_reply.started":"2024-11-29T09:53:55.551001Z","shell.execute_reply":"2024-11-29T10:03:14.609436Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/2: 1540batch [03:57,  6.49batch/s, accuracy=70.1, loss=0.578]                       \n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Loss: 0.5777, Accuracy: 70.14%\nValidation Accuracy: 74.45%\nModel saved with validation accuracy: 74.45%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/2: 1540batch [03:54,  6.56batch/s, accuracy=75, loss=0.523]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Loss: 0.5230, Accuracy: 75.00%\nValidation Accuracy: 75.42%\nModel saved with validation accuracy: 75.42%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"So the accuracy using LoRA reaches 75.42%.","metadata":{}}]}